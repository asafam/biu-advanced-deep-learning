{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import errno\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_spectogram(path):\n",
    "    \"\"\"\n",
    "    This method transforms wav audio files into spectograms\"\n",
    "    :param path the path to the wav file\n",
    "    \"\"\"\n",
    "    # TODO!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebsVoicePair(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset that on each iteration provides two random pairs of\n",
    "    celebrities voices. One pair is of the same person (positive sample), one\n",
    "    is of two different voices (negative sample)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root):\n",
    "        \"\"\"\n",
    "        This method constructs the data set by iterating the root directory, then\n",
    "        tranforming wav audio files to spectograms while maintining the speaker to \n",
    "        the voice spectogram so we can produce negative and postive samples upon __getitem__\n",
    "        \n",
    "        :param root the path to the speakers voices in the form of speaker_id/instances/*.wav\n",
    "        \"\"\"\n",
    "        # TODO!\n",
    "            \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # TODO!\n",
    "   \n",
    "    \n",
    "    def __len__(self):\n",
    "        # TODO!\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 64, 7)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 5)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 5)\n",
    "        self.fc1 = nn.Linear(2304, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        res = []\n",
    "        for i in range(2): # Siamese nets; sharing weights\n",
    "            x = data[i]\n",
    "            x = self.conv1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.pool1(x)\n",
    "            x = self.conv2(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.conv3(x)\n",
    "            x = F.relu(x)\n",
    "            \n",
    "            x = x.view(x.shape[0], -1)\n",
    "            x = self.fc1(x)\n",
    "            res.append(F.relu(x))\n",
    "            \n",
    "        res = torch.abs(res[1] - res[0])\n",
    "        res = self.fc2(res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method to train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, epoch, optimizer):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        for i in range(len(data)):\n",
    "            data[i] = data[i].to(device)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        output_positive = model(data[:2]) # TODO - get from data\n",
    "        output_negative = model(data[0:3:2]) # TODO - get from data\n",
    "        \n",
    "        target = target.type(torch.LongTensor).to(device)\n",
    "        target_positive = torch.squeeze(target[:,0]) # TODO - get from data\n",
    "        target_negative = torch.squeeze(target[:,1]) # TODO - get from data\n",
    "        \n",
    "        loss_positive = F.cross_entropy(output_positive, target_positive)\n",
    "        loss_negative = F.cross_entropy(output_negative, target_negative)\n",
    "        \n",
    "        loss = loss_positive + loss_negative\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, \n",
    "                                                                           batch_idx*batch_size, \n",
    "                                                                           len(train_loader.dataset), \n",
    "                                                                           100. * batch_idx*batch_size / len(train_loader.dataset), \n",
    "                                                                           loss.item()))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        accurate_labels = 0\n",
    "        all_labels = 0\n",
    "        loss = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            for i in range(len(data)):\n",
    "                data[i] = data[i].to(device)\n",
    "            \n",
    "            output_positive = model(data[:2]) # TODO - get from data\n",
    "            output_negative = model(data[0:3:2]) # TODO - get from data\n",
    "\n",
    "            target = target.type(torch.LongTensor).to(device)\n",
    "            target_positive = torch.squeeze(target[:,0]) # TODO - get from data\n",
    "            target_negative = torch.squeeze(target[:,1]) # TODO - get from data\n",
    "\n",
    "            loss_positive = F.cross_entropy(output_positive, target_positive)\n",
    "            loss_negative = F.cross_entropy(output_negative, target_negative)\n",
    "\n",
    "            loss = loss + loss_positive + loss_negative\n",
    "\n",
    "            accurate_labels_positive = torch.sum(torch.argmax(output_positive, dim=1) == target_positive).cpu()\n",
    "            accurate_labels_negative = torch.sum(torch.argmax(output_negative, dim=1) == target_negative).cpu()\n",
    "\n",
    "            accurate_labels = accurate_labels + accurate_labels_positive + accurate_labels_negative\n",
    "            all_labels = all_labels + len(target_positive) + len(target_negative)\n",
    "        \n",
    "        accuracy = 100. * accurate_labels / all_labels\n",
    "        print('Test accuracy: {}/{} ({:.3f}%)\\tLoss: {:.6f}'.format(accurate_labels, all_labels, accuracy, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneshot(model, device, data):\n",
    "   model.eval()\n",
    "\n",
    "   with torch.no_grad():\n",
    "      for i in range(len(data)):\n",
    "            data[i] = data[i].to(device)\n",
    "      \n",
    "      output = model(data)\n",
    "      return torch.squeeze(torch.argmax(output, dim=1)).cpu().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_learn = True\n",
    "save_frequency = 2\n",
    "batch_size = 16\n",
    "lr = 0.001\n",
    "num_epochs = 10\n",
    "weight_decay = 0.0001\n",
    "\n",
    "\n",
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "\n",
    "    model = Net().to(device)\n",
    "\n",
    "    if do_learn: # training mode\n",
    "        train_loader = torch.utils.data.DataLoader(BalancedMNISTPair('../data', train=True, download=True, transform=trans), batch_size=batch_size, shuffle=True)\n",
    "        test_loader = torch.utils.data.DataLoader(BalancedMNISTPair('../data', train=False, download=True, transform=trans), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        for epoch in range(num_epochs):\n",
    "            train(model, device, train_loader, epoch, optimizer)\n",
    "            test(model, device, test_loader)\n",
    "            if epoch & save_frequency == 0:\n",
    "                torch.save(model, 'siamese_{:03}.pt'.format(epoch))\n",
    "    else: # prediction\n",
    "        prediction_loader = torch.utils.data.DataLoader(BalancedMNISTPair('../data', train=False, download=True, transform=trans), batch_size=1, shuffle=True)\n",
    "        model.load_state_dict(torch.load(load_model_path))\n",
    "        data = []\n",
    "        data.extend(next(iter(prediction_loader))[0][:3:2])\n",
    "        same = oneshot(model, device, data)\n",
    "        if same > 0:\n",
    "            print('These two images are of the same number')\n",
    "        else:\n",
    "            print('These two images are not of the same number')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:biu-python] *",
   "language": "python",
   "name": "conda-env-biu-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
